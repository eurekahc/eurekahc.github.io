<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Today is a new day</title>
  <subtitle>Carrot&#39;s Tech Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2016-05-27T07:56:40.078Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>carrot</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图片引用测试</title>
    <link href="http://yoursite.com/2016/05/27/secondblog/"/>
    <id>http://yoursite.com/2016/05/27/secondblog/</id>
    <published>2016-05-27T07:39:25.000Z</published>
    <updated>2016-05-27T07:56:40.078Z</updated>
    
    <content type="html">&lt;p&gt;&lt;img src=&quot;/images/10DLT-CNN.jpg “来自: http://stats.stackexchange.com/questions/146413”&quot; alt=&quot;CNN&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/10DLT-CNN.jpg “来自: http://stats.stackexchange.com/questions/146413”&quot; alt=&quot;CNN&quot;&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>十个深度学习概念</title>
    <link href="http://yoursite.com/2016/05/27/%E5%8D%81%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5/"/>
    <id>http://yoursite.com/2016/05/27/十个深度学习概念/</id>
    <published>2016-05-27T06:51:16.000Z</published>
    <updated>2016-05-27T07:56:36.437Z</updated>
    
    <content type="html">&lt;h3 id=&quot;感知器（Perceptron）&quot;&gt;&lt;a href=&quot;#感知器（Perceptron）&quot; class=&quot;headerlink&quot; title=&quot;感知器（Perceptron）&quot;&gt;&lt;/a&gt;感知器（Perceptron）&lt;/h3&gt;&lt;p&gt;在人脑中，神经元是用于处理和传递信息的细胞。感知机可以认为是生物神经元的非常简化的版本。&lt;br&gt;感知器可以处理纪录数据，加权处理，给出一路输出。每一路输入的权重取决于对于输出的重要性。&lt;/p&gt;
&lt;h3 id=&quot;人工神经网络（Artificial-Neural-Networks）&quot;&gt;&lt;a href=&quot;#人工神经网络（Artificial-Neural-Networks）&quot; class=&quot;headerlink&quot; title=&quot;人工神经网络（Artificial Neural Networks）&quot;&gt;&lt;/a&gt;人工神经网络（Artificial Neural Networks）&lt;/h3&gt;&lt;p&gt;人工神经网络（ANN）是建模自生物神经网络，比如生物的中央神经系统和人类的大脑。&lt;br&gt;人工神经网络是处理装置，类似于小规模的松散地建模于哺乳动物大脑皮层的算法或者物理硬件。&lt;br&gt;我们可以称呼它为人脑的简单计算模型。&lt;/p&gt;
&lt;h3 id=&quot;向后传播（Backpropagation）&quot;&gt;&lt;a href=&quot;#向后传播（Backpropagation）&quot; class=&quot;headerlink&quot; title=&quot;向后传播（Backpropagation）&quot;&gt;&lt;/a&gt;向后传播（Backpropagation）&lt;/h3&gt;&lt;p&gt;神经网络模型训练常用的一种算法是向后传播算法。训练神经网络会先给定一组输入，这会产品一定的输出。训练神经网络的第一步是告诉神经网络这样的输入获得这样的输出是正确的，理想的。人工神经网络根据这个理想的输出来调整各项权重，使得下次获得相似输入时可以获得更准确的输出（取决于他们对于整个预测模型的贡献）。&lt;br&gt;整个过程会反复进行直到输入和理想输出间的误差是可以接受的。&lt;/p&gt;
&lt;h3 id=&quot;卷积神经网络（Convolutional-Neural-Networks）&quot;&gt;&lt;a href=&quot;#卷积神经网络（Convolutional-Neural-Networks）&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络（Convolutional Neural Networks）&quot;&gt;&lt;/a&gt;卷积神经网络（Convolutional Neural Networks）&lt;/h3&gt;&lt;p&gt;卷积神经网络可以被认为是由大量相同神经元复制得到的神经网络。这使得网络只需要学习一个神经元一次，就可以在许多地方应用，简化了模型训练过程，并减少了误差。所以卷积神经网络在特别适合应用于物体识别和图像标注。&lt;br&gt;卷积神经网络不断学习输入的卷积抽象表达。在以下这个物体识别例子中，卷积神经网络从学习像素数据开始，然后学习可区分的特征，比如边缘，基本形状，复杂形状，模式和纹理。&lt;br&gt;&lt;img src=&quot;/images/10DLT-CNN.jpg “来自: http://stats.stackexchange.com/questions/146413”&quot; alt=&quot;CNN&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;时间递归神经网络（Recurrent-Neural-Network）&quot;&gt;&lt;a href=&quot;#时间递归神经网络（Recurrent-Neural-Network）&quot; class=&quot;headerlink&quot; title=&quot;时间递归神经网络（Recurrent Neural Network）&quot;&gt;&lt;/a&gt;时间递归神经网络（Recurrent Neural Network）&lt;/h3&gt;&lt;p&gt;递归神经网络用于处理连续信号。和传统的神经网络认为所有的输入和输出间是相互独立的不同，递归神经网络依赖于之前的计算。递归神经网络是神经网络在时间上的展开。传统神经网络可以有不同层，但是RNN在每个时间点只有相同的层，并将输出作为下一个时间点的输入。RNN中实体间的连接形成一个定向周期，形成一定的内部记忆，帮助模型处理长长的依赖链。&lt;/p&gt;
&lt;h3 id=&quot;结构递归神经网络（Recursive-Neural-Network）&quot;&gt;&lt;a href=&quot;#结构递归神经网络（Recursive-Neural-Network）&quot; class=&quot;headerlink&quot; title=&quot;结构递归神经网络（Recursive Neural Network）&quot;&gt;&lt;/a&gt;结构递归神经网络（Recursive Neural Network）&lt;/h3&gt;&lt;p&gt;结构递归神经网络是时间递归神经网络的推广应用，它是一系列不变的权重系数复制或者递归应用于结构上而形成。结构递归神经网络可以表示成树形结构，而时间递归神经网络是一个时序链。结构递归神经网络可用于解决自然语言理解中一些问题，如语义情感分析。&lt;br&gt;&lt;img src=&quot;/images/10DLT-RNN.jpg “来自: http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf”&quot; alt=&quot;RNN&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;监督学习神经网络-（Supervised-Neural-Network）&quot;&gt;&lt;a href=&quot;#监督学习神经网络-（Supervised-Neural-Network）&quot; class=&quot;headerlink&quot; title=&quot;监督学习神经网络 （Supervised Neural Network）&quot;&gt;&lt;/a&gt;监督学习神经网络 （Supervised Neural Network）&lt;/h3&gt;&lt;p&gt;监督学习神经网络想要获得一个理想的输出，必须之前有给定一个准确的输出。“训练”是基于一个事先定义的数据集合，基于这个数据集合，在给定输入时产生准确的输出。所以监督学习类似于已经给出了问题和理想回答的学习。&lt;/p&gt;
&lt;h3 id=&quot;无监督学习神经网络-（Unsupervised-Neural-Network）&quot;&gt;&lt;a href=&quot;#无监督学习神经网络-（Unsupervised-Neural-Network）&quot; class=&quot;headerlink&quot; title=&quot;无监督学习神经网络 （Unsupervised Neural Network）&quot;&gt;&lt;/a&gt;无监督学习神经网络 （Unsupervised Neural Network）&lt;/h3&gt;&lt;p&gt;无监督学习需要一个程序或者机制，可以自动在一个事先没有训练过的没有标记过的数据集合中运用聚类算法自动发现模式和倾向。&lt;/p&gt;
&lt;h3 id=&quot;梯度下降（Gradient-Descent）&quot;&gt;&lt;a href=&quot;#梯度下降（Gradient-Descent）&quot; class=&quot;headerlink&quot; title=&quot;梯度下降（Gradient Descent）&quot;&gt;&lt;/a&gt;梯度下降（Gradient Descent）&lt;/h3&gt;&lt;p&gt;梯度下降法是寻找函数局部最小值的算法。算法先猜测一个局部最小值的点，计算梯度，并沿着梯度负方向反复使用梯度算法直到找到局部最小值，即算法最终收敛于梯度为0的点。我们其实是在沿着误差表面下降，直到到达谷底。&lt;/p&gt;
&lt;h3 id=&quot;字嵌入（Word-Embedding）&quot;&gt;&lt;a href=&quot;#字嵌入（Word-Embedding）&quot; class=&quot;headerlink&quot; title=&quot;字嵌入（Word Embedding）&quot;&gt;&lt;/a&gt;字嵌入（Word Embedding）&lt;/h3&gt;&lt;p&gt;就像一幅画作可以代表一个人，字嵌入是一个单词的数字表征。字嵌入经过训练，用来计算单词间的相似度。是计算机能够理解的单词的语义和语法的数字表达。&lt;br&gt;这个过程中创建的单词向量能获得看起来感觉很神奇的特征，比如，从“国王”的向量中减去“男人”的向量的结果会近似相等于“王后”中减去“女人”。更有意思的是，跑减去正在跑和看减去正在看的值近似。这卓明模型不仅学习了单词的意思和语义，还学习了一定程度的句法和语法。&lt;br&gt;&lt;img src=&quot;/images/10DLT-10DLT-WE.jpg&quot; alt=&quot;10DLT-WE&quot;&gt;&lt;/p&gt;
&lt;p&gt;翻译自： &lt;a href=&quot;http://www.datasciencecentral.com/profiles/blogs/10-deep-learning-terms-explained-in-simple-english&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.datasciencecentral.com/profiles/blogs/10-deep-learning-terms-explained-in-simple-english&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;感知器（Perceptron）&quot;&gt;&lt;a href=&quot;#感知器（Perceptron）&quot; class=&quot;headerlink&quot; title=&quot;感知器（Perceptron）&quot;&gt;&lt;/a&gt;感知器（Perceptron）&lt;/h3&gt;&lt;p&gt;在人脑中，神经元是用于处理和传递信息
    
    </summary>
    
    
      <category term="机器学习 深度学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>firstblog</title>
    <link href="http://yoursite.com/2016/05/11/firstblog/"/>
    <id>http://yoursite.com/2016/05/11/firstblog/</id>
    <published>2016-05-11T07:19:35.000Z</published>
    <updated>2016-05-11T07:19:35.183Z</updated>
    
    <content type="html"></content>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2016/05/11/hello-world/"/>
    <id>http://yoursite.com/2016/05/11/hello-world/</id>
    <published>2016-05-11T03:19:06.745Z</published>
    <updated>2016-05-11T03:19:06.748Z</updated>
    
    <content type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Writing&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Run-server&quot;&gt;&lt;a href=&quot;#Run-server&quot; class=&quot;headerlink&quot; title=&quot;Run server&quot;&gt;&lt;/a&gt;Run server&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo server&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/server.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Server&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Generate-static-files&quot;&gt;&lt;a href=&quot;#Generate-static-files&quot; class=&quot;headerlink&quot; title=&quot;Generate static files&quot;&gt;&lt;/a&gt;Generate static files&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo generate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/generating.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Generating&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Deploy-to-remote-sites&quot;&gt;&lt;a href=&quot;#Deploy-to-remote-sites&quot; class=&quot;headerlink&quot; title=&quot;Deploy to remote sites&quot;&gt;&lt;/a&gt;Deploy to remote sites&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/deployment.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Deployment&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
</feed>
